{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_KEYWORDS_PER_CLUSTER = 15\n",
    "PATH_TO_FILE = '/Users/lukamedvidovic/Downloads/Call Centre Enquiry Data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukamedvidovic/opt/miniconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 68\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m# Get top issues for each column and plot\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mcolumns:\n\u001b[0;32m---> 68\u001b[0m     top_issues, cluster_descriptions, silhouette, dbi \u001b[39m=\u001b[39m get_top_issues(column)\n\u001b[1;32m     69\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCluster descriptions for \u001b[39m\u001b[39m{\u001b[39;00mcolumn\u001b[39m}\u001b[39;00m\u001b[39m ranked by frequency (Silhouette score: \u001b[39m\u001b[39m{\u001b[39;00msilhouette\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Davies-Bouldin index: \u001b[39m\u001b[39m{\u001b[39;00mdbi\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m     \u001b[39mfor\u001b[39;00m cluster, count \u001b[39min\u001b[39;00m top_issues\u001b[39m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[3], line 58\u001b[0m, in \u001b[0;36mget_top_issues\u001b[0;34m(column, max_clusters)\u001b[0m\n\u001b[1;32m     55\u001b[0m     cluster_descriptions[i] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(cluster_terms)\n\u001b[1;32m     57\u001b[0m \u001b[39m# Calculate Silhouette score and Davies-Bouldin index\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m silhouette \u001b[39m=\u001b[39m silhouette_score(X, clusters)\n\u001b[1;32m     59\u001b[0m dbi \u001b[39m=\u001b[39m davies_bouldin_score(X\u001b[39m.\u001b[39mtoarray(), clusters)\n\u001b[1;32m     61\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSilhouette score ranges from -1 to 1. Higher values indicate better clustering.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py:131\u001b[0m, in \u001b[0;36msilhouette_score\u001b[0;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m         X, labels \u001b[39m=\u001b[39m X[indices], labels[indices]\n\u001b[0;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(silhouette_samples(X, labels, metric\u001b[39m=\u001b[39;49mmetric, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/sklearn/metrics/cluster/_unsupervised.py:283\u001b[0m, in \u001b[0;36msilhouette_samples\u001b[0;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[1;32m    279\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m metric\n\u001b[1;32m    280\u001b[0m reduce_func \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m    281\u001b[0m     _silhouette_reduce, labels\u001b[39m=\u001b[39mlabels, label_freqs\u001b[39m=\u001b[39mlabel_freqs\n\u001b[1;32m    282\u001b[0m )\n\u001b[0;32m--> 283\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49mpairwise_distances_chunked(X, reduce_func\u001b[39m=\u001b[39;49mreduce_func, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    284\u001b[0m intra_clust_dists, inter_clust_dists \u001b[39m=\u001b[39m results\n\u001b[1;32m    285\u001b[0m intra_clust_dists \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(intra_clust_dists)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:2017\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   2015\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2016\u001b[0m     X_chunk \u001b[39m=\u001b[39m X[sl]\n\u001b[0;32m-> 2017\u001b[0m D_chunk \u001b[39m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[39m=\u001b[39;49mmetric, n_jobs\u001b[39m=\u001b[39;49mn_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   2018\u001b[0m \u001b[39mif\u001b[39;00m (X \u001b[39mis\u001b[39;00m Y \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[39m.\u001b[39mget(\n\u001b[1;32m   2019\u001b[0m     metric, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2020\u001b[0m ) \u001b[39mis\u001b[39;00m euclidean_distances:\n\u001b[1;32m   2021\u001b[0m     \u001b[39m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m     \u001b[39m# i.e. \"l2\"\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m     D_chunk\u001b[39m.\u001b[39mflat[sl\u001b[39m.\u001b[39mstart :: _num_samples(X) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:2195\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2192\u001b[0m         \u001b[39mreturn\u001b[39;00m distance\u001b[39m.\u001b[39msquareform(distance\u001b[39m.\u001b[39mpdist(X, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[1;32m   2193\u001b[0m     func \u001b[39m=\u001b[39m partial(distance\u001b[39m.\u001b[39mcdist, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m-> 2195\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1765\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1762\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1764\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1765\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1767\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:338\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[39mif\u001b[39;00m Y_norm_squared\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m (\u001b[39m1\u001b[39m, Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[1;32m    333\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    334\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIncompatible dimensions for Y of shape \u001b[39m\u001b[39m{\u001b[39;00mY\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    335\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mY_norm_squared of shape \u001b[39m\u001b[39m{\u001b[39;00moriginal_shape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    336\u001b[0m         )\n\u001b[0;32m--> 338\u001b[0m \u001b[39mreturn\u001b[39;00m _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:379\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    376\u001b[0m     distances \u001b[39m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[1;32m    377\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     \u001b[39m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m     distances \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m safe_sparse_dot(X, Y\u001b[39m.\u001b[39;49mT, dense_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    380\u001b[0m     distances \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m XX\n\u001b[1;32m    381\u001b[0m     distances \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m YY\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/sklearn/utils/extmath.py:193\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    191\u001b[0m         ret \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(a, b)\n\u001b[1;32m    192\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 193\u001b[0m     ret \u001b[39m=\u001b[39m a \u001b[39m@\u001b[39;49m b\n\u001b[1;32m    195\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    196\u001b[0m     sparse\u001b[39m.\u001b[39missparse(a)\n\u001b[1;32m    197\u001b[0m     \u001b[39mand\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(b)\n\u001b[1;32m    198\u001b[0m     \u001b[39mand\u001b[39;00m dense_output\n\u001b[1;32m    199\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ret, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    200\u001b[0m ):\n\u001b[1;32m    201\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39mtoarray()\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/scipy/sparse/_base.py:630\u001b[0m, in \u001b[0;36mspmatrix.__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m isscalarlike(other):\n\u001b[1;32m    628\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mScalar operands are not allowed, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    629\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39muse \u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 630\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mul_dispatch(other)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/scipy/sparse/_base.py:541\u001b[0m, in \u001b[0;36mspmatrix._mul_dispatch\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m other\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m    540\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mdimension mismatch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 541\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mul_sparse_matrix(other)\n\u001b[1;32m    543\u001b[0m \u001b[39m# If it's a list or whatever, treat it like a matrix\u001b[39;00m\n\u001b[1;32m    544\u001b[0m other_a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(other)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.10/site-packages/scipy/sparse/_compressed.py:518\u001b[0m, in \u001b[0;36m_cs_matrix._mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    514\u001b[0m idx_dtype \u001b[39m=\u001b[39m get_index_dtype((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindptr, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices,\n\u001b[1;32m    515\u001b[0m                              other\u001b[39m.\u001b[39mindptr, other\u001b[39m.\u001b[39mindices))\n\u001b[1;32m    517\u001b[0m fn \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(_sparsetools, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_matmat_maxnnz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 518\u001b[0m nnz \u001b[39m=\u001b[39m fn(M, N,\n\u001b[1;32m    519\u001b[0m          np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindptr, dtype\u001b[39m=\u001b[39;49midx_dtype),\n\u001b[1;32m    520\u001b[0m          np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices, dtype\u001b[39m=\u001b[39;49midx_dtype),\n\u001b[1;32m    521\u001b[0m          np\u001b[39m.\u001b[39;49masarray(other\u001b[39m.\u001b[39;49mindptr, dtype\u001b[39m=\u001b[39;49midx_dtype),\n\u001b[1;32m    522\u001b[0m          np\u001b[39m.\u001b[39;49masarray(other\u001b[39m.\u001b[39;49mindices, dtype\u001b[39m=\u001b[39;49midx_dtype))\n\u001b[1;32m    524\u001b[0m idx_dtype \u001b[39m=\u001b[39m get_index_dtype((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindptr, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices,\n\u001b[1;32m    525\u001b[0m                              other\u001b[39m.\u001b[39mindptr, other\u001b[39m.\u001b[39mindices),\n\u001b[1;32m    526\u001b[0m                             maxval\u001b[39m=\u001b[39mnnz)\n\u001b[1;32m    528\u001b[0m indptr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(major_axis \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39midx_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(PATH_TO_FILE)\n",
    "\n",
    "# Define custom stopwords\n",
    "custom_stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "# Initialize TF-IDF Vectorizer with custom stopwords\n",
    "vectorizer = TfidfVectorizer(stop_words=custom_stopwords)\n",
    "\n",
    "# Define function to get top issues for a given column\n",
    "def get_top_issues(column, max_clusters=15):\n",
    "    # Extract subjects for the given column\n",
    "    column_data = df[column].dropna()\n",
    "\n",
    "    # Vectorize the subjects\n",
    "    X = vectorizer.fit_transform(column_data)\n",
    "\n",
    "    # Find the optimal number of clusters using the elbow method\n",
    "    wcss = []\n",
    "    for i in range(1, max_clusters+1):\n",
    "        kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "        kmeans.fit(X)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    elbow_points = np.where(np.gradient(wcss) > np.max(wcss)*0.1)[0]\n",
    "    elbow_point = elbow_points[0] if len(elbow_points) > 0 else 15\n",
    "\n",
    "    # Initialize KMeans with the optimal number of clusters\n",
    "    km = KMeans(n_clusters=elbow_point, random_state=42)\n",
    "\n",
    "    # Fit KMeans on the data\n",
    "    km.fit(X)\n",
    "\n",
    "    # Predict the clusters\n",
    "    clusters = km.predict(X)\n",
    "\n",
    "    # Count the frequency of each cluster\n",
    "    cluster_counts = pd.Series(clusters).value_counts()\n",
    "\n",
    "    # Get the cluster centers\n",
    "    order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Generate descriptions for each cluster\n",
    "    cluster_descriptions = {}\n",
    "    for i in range(elbow_point):\n",
    "        cluster_terms = [terms[ind] for ind in order_centroids[i, :NUM_OF_KEYWORDS_PER_CLUSTER]]\n",
    "        cluster_descriptions[i] = ' '.join(cluster_terms)\n",
    "\n",
    "    # Calculate Silhouette score and Davies-Bouldin index\n",
    "    silhouette = silhouette_score(X, clusters)\n",
    "    dbi = davies_bouldin_score(X.toarray(), clusters)\n",
    "\n",
    "    print('Silhouette score ranges from -1 to 1. Higher values indicate better clustering.')\n",
    "    print('Davies-Bouldin index values start from 0. Lower values indicate better clustering.')\n",
    "    # Return the cluster counts, descriptions, and quality metrics\n",
    "    return cluster_counts, cluster_descriptions, silhouette, dbi\n",
    "\n",
    "# Get top issues for each column and plot\n",
    "for column in df.columns:\n",
    "    top_issues, cluster_descriptions, silhouette, dbi = get_top_issues(column)\n",
    "    print(f\"\\nCluster descriptions for {column} ranked by frequency (Silhouette score: {silhouette:.2f}, Davies-Bouldin index: {dbi:.2f}):\\n\")\n",
    "    for cluster, count in top_issues.items():\n",
    "        print(f\"Cluster {cluster}: {cluster_descriptions[cluster]} (Frequency: {count})\")\n",
    "    top_issues.plot(kind='bar', figsize=(12, 6))\n",
    "    plt.title(f\"Top Issues for {column}\")\n",
    "    plt.xlabel(\"Cluster\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
